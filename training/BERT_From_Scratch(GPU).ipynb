{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JCi98erVCQK",
        "outputId": "ecca986c-a916-4035-ef7f-871904a3dbc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16\n"
          ]
        }
      ],
      "source": [
        "!pip3 install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dz2vJKUOQUt",
        "outputId": "c02ab279-52a3-4f9a-de8e-debb5716a2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "edW_xzmlOiK-"
      },
      "outputs": [],
      "source": [
        "data = \"/content/drive/MyDrive/Colab_Notebooks/NLP/Assignment5/data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1k9DLZMAOhc5"
      },
      "outputs": [],
      "source": [
        "!cp -R $data ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSz5jzj61nHc"
      },
      "source": [
        "# BERT\n",
        "\n",
        "We shall implement BERT.  For this tutorial, you may want to first look at my Transformers tutorial to get a basic understanding of Transformers.\n",
        "\n",
        "For BERT, the main difference is on how we process the datasets, i.e., masking.   Aside from that, the backbone model is still the Transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-8kZmr4ItGUj"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import re\n",
        "from   random import *\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "SEED = 999\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0fCMwESgeKy",
        "outputId": "297526f2-5d41-4d0f-8038-cba138458939"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8lgGB2yZXwQ"
      },
      "source": [
        "## 1. Data\n",
        "\n",
        "For simplicity, we shall use very simple data like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNiqty9B6-go",
        "outputId": "3249ffa6-6392-4e69-e220-d1c3cacc50e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "\n",
        "from nltk.corpus import brown\n",
        "\n",
        "brown.categories()\n",
        "sentences2_list = brown.sents(categories=\"government\")\n",
        "raw_text2 = \"\".join([\" \".join(sent) for sent in sentences2_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c9RpYlCn70UO"
      },
      "outputs": [],
      "source": [
        "# raw_text2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PiCQJZSBsFew"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(raw_text2)\n",
        "sentences = list(doc.sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nW1t19r3pRYg"
      },
      "outputs": [],
      "source": [
        "# import spacy\n",
        "\n",
        "# with open (\"data/book1.txt\", \"r\") as f:\n",
        "#     raw_text = f.read()\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "# doc = nlp(raw_text)\n",
        "# sentences = list(doc.sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f1WmIb9Xpj5v"
      },
      "outputs": [],
      "source": [
        "# type(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vYfyTj97UL2s"
      },
      "outputs": [],
      "source": [
        "# # Sayar Minn\n",
        "\n",
        "# # Load a portion of the WikiAnswers dataset\n",
        "# dataset = load_dataset(\"embedding-data/QQP_triplets\")\n",
        "\n",
        "# text = []\n",
        "# for i in range(len(dataset['train'])):\n",
        "#     all_sents = [dataset['train'][i]['set']['query']] + dataset['train'][i]['set']['pos'] + dataset['train'][i]['set']['neg']\n",
        "#     text.extend(all_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "r_OLfj-KZXwQ"
      },
      "outputs": [],
      "source": [
        "text = [x.text.lower() for x in sentences] #lower case\n",
        "text = [re.sub(\"[.,!?\\\\-]\", '', x) for x in text] #clean all symbols\n",
        "\n",
        "# text = [x.lower() for x in text] #lower case\n",
        "# text = [re.sub(\"[.,!?\\\\-]\", '', x) for x in text] #clean all symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUF63AvQZXwS",
        "outputId": "6fc33ad2-5c08-436a-8733-27d8b45a980e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the office of business economics ( obe ) of the us department of commerce provides basic measures of the national economy and current analysis of shortrun changes in the economic situation and business outlook it develops and analyzes the national income  balance of international payments  and many other business indicators such measures are essential to its job of presenting business and government with the facts required to meet the objective of expanding business and improving the operation of the economy contactfor _____\n",
            "['the', 'office', 'of', 'business', 'economics', '(', 'obe', ')', 'of', 'the', 'us', 'department', 'of', 'commerce', 'provides', 'basic', 'measures', 'of', 'the', 'national', 'economy', 'and', 'current', 'analysis', 'of', 'shortrun', 'changes', 'in', 'the', 'economic', 'situation', 'and', 'business', 'outlook', 'it', 'develops', 'and', 'analyzes', 'the', 'national', 'income', 'balance', 'of', 'international', 'payments', 'and', 'many', 'other', 'business', 'indicators', 'such', 'measures', 'are', 'essential', 'to', 'its', 'job', 'of', 'presenting', 'business', 'and', 'government', 'with', 'the', 'facts', 'required', 'to', 'meet', 'the', 'objective', 'of', 'expanding', 'business', 'and', 'improving', 'the', 'operation', 'of', 'the', 'economy', 'contactfor']\n"
          ]
        }
      ],
      "source": [
        "for sentence in text:\n",
        "    print(sentence, \"_____\")\n",
        "    words = sentence.split()\n",
        "    print(words)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSFG2AAcIGab",
        "outputId": "0761ec55-5ae5-424f-8d59-ae86cdedd636"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1294"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mC5Y_J6mVqEm"
      },
      "outputs": [],
      "source": [
        "# sentences = text[0:10000]\n",
        "# text = text[0:10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F8xAoC1ZXwS"
      },
      "source": [
        "### Making vocabs\n",
        "\n",
        "Before making the vocabs, let's remove all question marks and perios, etc, then turn everything to lowercase, and then simply split the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AhX8b1ydtrVf"
      },
      "outputs": [],
      "source": [
        "# combine everything into one to make vocabs\n",
        "word_list = list(set(\" \".join(text).split()))\n",
        "word2id = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, '[UNK]': 4}  #special tokens.\n",
        "\n",
        "#create the word2id\n",
        "for i, w in enumerate(word_list):\n",
        "    word2id[w] = i + 5  #because 0-3 are already occupied\n",
        "    id2word = {i: w for i, w in enumerate(word2id)}\n",
        "    vocab_size = len(word2id)\n",
        "\n",
        "#list of all tokens for whole text\n",
        "token_list = list()\n",
        "for sentence in text:\n",
        "    arr = [word2id[word] for word in sentence.split()]\n",
        "    token_list.append(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Tgf-YAmnWFex"
      },
      "outputs": [],
      "source": [
        "bert_args = dict()\n",
        "bert_args['vocab_size'] = vocab_size\n",
        "bert_args['word2id'] = word2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgMoh2lQZXwT",
        "outputId": "bb2b9efd-83e1-4aaf-c415-933cda230e6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "The Office of Business Economics ( OBE ) of the U.S. Department of Commerce provides basic measures of the national economy and current analysis of short-run changes in the economic situation and business outlook .It develops and analyzes the national income , balance of international payments , and many other business indicators .Such measures are essential to its job of presenting business and Government with the facts required to meet the objective of expanding business and improving the operation of the economy .ContactFor"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#take a look at sentences\n",
        "sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pZ42SFLKtsv_"
      },
      "outputs": [],
      "source": [
        "#take a look at token_list\n",
        "# token_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iOm9Ow1dZXwU"
      },
      "outputs": [],
      "source": [
        "# #testing one sentence\n",
        "# for tokens in token_list[0]:\n",
        "#     print(id2word[tokens])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGj-D9VgZXwV"
      },
      "source": [
        "## 2. Data loader\n",
        "\n",
        "We gonna make dataloader.  Inside here, we need to make two types of embeddings: **token embedding** and **segment embedding**\n",
        "\n",
        "1. **Token embedding** - Given “The cat is walking. The dog is barking”, we add [CLS] and [SEP] >> “[CLS] the cat is walking [SEP] the dog is barking”.\n",
        "\n",
        "2. **Segment embedding**\n",
        "A segment embedding separates two sentences, i.e., [0 0 0 0 1 1 1 1 ]\n",
        "\n",
        "3. **Masking**\n",
        "As mentioned in the original paper, BERT randomly assigns masks to 15% of the sequence. In this 15%, 80% is replaced with masks, while 10% is replaced with random tokens, and the rest 10% is left as is.  Here we specified `max_pred`\n",
        "\n",
        "4. **Padding**\n",
        "Once we mask, we will add padding. For simplicity, here we padded until some specified `max_len`.\n",
        "\n",
        "Note:  `positive` and `negative` are just simply counts to keep track of the batch size.  `positive` refers to two sentences that are really next to one another."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "I1VfwcnEZXwV"
      },
      "outputs": [],
      "source": [
        "batch_size = 6\n",
        "max_mask   = 5  # max masked tokens when 15% exceed, it will only be max_pred\n",
        "max_len    = 1000 # maximum of length to be padded;\n",
        "\n",
        "bert_args['batch_size'] = batch_size\n",
        "bert_args['max_mask'] = max_mask\n",
        "bert_args['max_len'] = max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TtyOOmRntu8w"
      },
      "outputs": [],
      "source": [
        "def make_batch():\n",
        "    batch = []\n",
        "    positive = negative = 0  #count of batch size;  we want to have half batch that are positive pairs (i.e., next sentence pairs)\n",
        "    while positive != batch_size/2 or negative != batch_size/2:\n",
        "\n",
        "        #randomly choose two sentence so we can put [SEP]\n",
        "        tokens_a_index, tokens_b_index= randrange(len(sentences)), randrange(len(sentences))\n",
        "        #retrieve the two sentences\n",
        "        tokens_a, tokens_b= token_list[tokens_a_index], token_list[tokens_b_index]\n",
        "\n",
        "        #1. token embedding - append CLS and SEP\n",
        "        input_ids = [word2id['[CLS]']] + tokens_a + [word2id['[SEP]']] + tokens_b + [word2id['[SEP]']]\n",
        "\n",
        "        #2. segment embedding - [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        #3. mask language modeling\n",
        "        #masked 15%, but should be at least 1 but does not exceed max_mask\n",
        "        n_pred =  min(max_mask, max(1, int(round(len(input_ids) * 0.15))))\n",
        "        #get the pos that excludes CLS and SEP and shuffle them\n",
        "        cand_maked_pos = [i for i, token in enumerate(input_ids) if token != word2id['[CLS]'] and token != word2id['[SEP]']]\n",
        "        shuffle(cand_maked_pos)\n",
        "        masked_tokens, masked_pos = [], []\n",
        "        #simply loop and change the input_ids to [MASK]\n",
        "        for pos in cand_maked_pos[:n_pred]:\n",
        "            masked_pos.append(pos)  #remember the position\n",
        "            masked_tokens.append(input_ids[pos]) #remember the tokens\n",
        "            #80% replace with a [MASK], but 10% will replace with a random token\n",
        "            if random() < 0.1:  # 10%\n",
        "                index = randint(0, vocab_size - 1) # random index in vocabulary\n",
        "                input_ids[pos] = word2id[id2word[index]] # replace\n",
        "            elif random() < 0.9:  # 80%\n",
        "                input_ids[pos] = word2id['[MASK]'] # make mask\n",
        "            else:  #10% do nothing\n",
        "                pass\n",
        "\n",
        "        # pad the input_ids and segment ids until the max len\n",
        "        n_pad = max_len - len(input_ids)\n",
        "        input_ids.extend([0] * n_pad)\n",
        "        segment_ids.extend([0] * n_pad)\n",
        "\n",
        "        # pad the masked_tokens and masked_pos to make sure the lenth is max_mask\n",
        "        if max_mask > n_pred:\n",
        "            n_pad = max_mask - n_pred\n",
        "            masked_tokens.extend([0] * n_pad)\n",
        "            masked_pos.extend([0] * n_pad)\n",
        "\n",
        "        #check if first sentence is really comes before the second sentence\n",
        "        #also make sure positive is exactly half the batch size\n",
        "        if tokens_a_index + 1 == tokens_b_index and positive < batch_size / 2:\n",
        "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True]) # IsNext\n",
        "            positive += 1\n",
        "        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2:\n",
        "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False]) # NotNext\n",
        "            negative += 1\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Q7_HC-Y0jC3K"
      },
      "outputs": [],
      "source": [
        "batch = make_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i49LYZpJZXwW",
        "outputId": "2f74712f-724e-4285-81f1-2f6e6deef1ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#len of batch\n",
        "len(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sct7bBZZXwX",
        "outputId": "6eaad044-9b6c-46f7-c5a4-f6bc4fa52ffd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6, 1000]),\n",
              " torch.Size([6, 1000]),\n",
              " torch.Size([6, 5]),\n",
              " torch.Size([6, 5]),\n",
              " torch.Size([6]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#we can deconstruct using map and zip\n",
        "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
        "\n",
        "# input_ids = input_ids.to(device)\n",
        "# segment_ids = segment_ids.to(device)\n",
        "# masked_tokens = masked_tokens.to(device)\n",
        "# masked_pos = masked_pos.to(device)\n",
        "# isNext = isNext.to(device)\n",
        "\n",
        "input_ids.shape, segment_ids.shape, masked_tokens.shape, masked_pos.shape, isNext.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc8GjKDXgXbA",
        "outputId": "420ee9b2-24d6-4780-ca7d-f41e17e8e032"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "input_ids.get_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZfGH3ByZXwX"
      },
      "source": [
        "## 3. Model\n",
        "\n",
        "Recall that BERT only uses the encoder.\n",
        "\n",
        "BERT has the following components:\n",
        "\n",
        "- Embedding layers\n",
        "- Attention Mask\n",
        "- Encoder layer\n",
        "- Multi-head attention\n",
        "- Scaled dot product attention\n",
        "- Position-wise feed-forward network\n",
        "- BERT (assembling all the components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZXPZFFNZXwX"
      },
      "source": [
        "## 3.1 Embedding\n",
        "\n",
        "Here we simply generate the positional embedding, and sum the token embedding, positional embedding, and segment embedding together.\n",
        "\n",
        "<img src = \"figures/BERT_embed.png\" width=500>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5lGdemo7ZXwX"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.tok_embed = nn.Embedding(vocab_size, d_model).to(device)  # token embedding\n",
        "        self.pos_embed = nn.Embedding(max_len, d_model).to(device)      # position embedding\n",
        "        self.seg_embed = nn.Embedding(n_segments, d_model).to(device)  # segment(token type) embedding\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, seg):\n",
        "        #x, seg: (bs, len)\n",
        "        seq_len = x.size(1)\n",
        "        pos = torch.arange(seq_len, dtype=torch.long, device=device)\n",
        "        pos = pos.unsqueeze(0).expand_as(x)  # (len,) -> (bs, len)\n",
        "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
        "        return self.norm(embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KADjrJ2cZXwX"
      },
      "source": [
        "## 3.2 Attention mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "s1PGksqBNuZM"
      },
      "outputs": [],
      "source": [
        "def get_attn_pad_mask(seq_q, seq_k):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    # eq(zero) is PAD token\n",
        "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1).to(device)  # batch_size x 1 x len_k(=len_q), one is masking\n",
        "    return pad_attn_mask.expand(batch_size, len_q, len_k).to(device)  # batch_size x len_q x len_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7KwBPTWZXwY"
      },
      "source": [
        "### Testing the attention mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wDrtoc3ZXwY",
        "outputId": "7388e43b-c84a-4fd5-d429-4b0417f11413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 1000, 1000])\n"
          ]
        }
      ],
      "source": [
        "print(get_attn_pad_mask(input_ids, input_ids).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyWyx2DrZXwY"
      },
      "source": [
        "## 3.3 Encoder\n",
        "\n",
        "The encoder has two main components:\n",
        "\n",
        "- Multi-head Attention\n",
        "- Position-wise feed-forward network\n",
        "\n",
        "First let's make the wrapper called `EncoderLayer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kNLCqvcVZXwY"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.enc_self_attn = MultiHeadAttention().to(device)\n",
        "        self.pos_ffn       = PoswiseFeedForwardNet().to(device)\n",
        "\n",
        "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
        "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
        "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
        "        return enc_outputs, attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egNl314HZXwY"
      },
      "source": [
        "Let's define the scaled dot attention, to be used inside the multihead attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eaHzVYVWZXwZ"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
        "        attn = nn.Softmax(dim=-1)(scores)\n",
        "        context = torch.matmul(attn, V)\n",
        "        return context, attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l4rJBmNZXwZ"
      },
      "source": [
        "Let's define the parameters first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ttKFbZRWZXwa"
      },
      "outputs": [],
      "source": [
        "n_layers = 6    # number of Encoder of Encoder Layer\n",
        "n_heads  = 8    # number of heads in Multi-Head Attention\n",
        "d_model  = 768  # Embedding Size\n",
        "d_ff = 768 * 4  # 4*d_model, FeedForward dimension\n",
        "d_k = d_v = 64  # dimension of K(=Q), V\n",
        "n_segments = 2\n",
        "\n",
        "bert_args['n_layers'] = n_layers\n",
        "bert_args['n_heads'] = n_heads\n",
        "bert_args['d_model'] = d_model\n",
        "bert_args['d_ff'] = d_ff\n",
        "bert_args['d_k'] = d_k\n",
        "bert_args['d_v'] = d_v\n",
        "bert_args['n_segments'] = n_segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reZUgaX-ZXwa"
      },
      "source": [
        "Here is the Multiheadattention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xr4axMooZXwb"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.W_Q = nn.Linear(d_model, d_k * n_heads).to(device)\n",
        "        self.W_K = nn.Linear(d_model, d_k * n_heads).to(device)\n",
        "        self.W_V = nn.Linear(d_model, d_v * n_heads).to(device)\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
        "        residual, batch_size = Q, Q.size(0)\n",
        "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
        "        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
        "        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1).to(device) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
        "\n",
        "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
        "        output = nn.Linear(n_heads * d_v, d_model).to(device)(context)\n",
        "\n",
        "        return nn.LayerNorm(d_model).to(device)(output + residual), attn # output: [batch_size x len_q x d_model]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djJvdFtwZXwb"
      },
      "source": [
        "Here is the PoswiseFeedForwardNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Lbd882gmZXwb"
      },
      "outputs": [],
      "source": [
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
        "        return self.fc2(F.gelu(self.fc1(x)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBc2QUZuZXwb"
      },
      "source": [
        "## 3.4 Putting them together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "OZ0TJ84W4SZw"
      },
      "outputs": [],
      "source": [
        "class BERT(nn.Module):\n",
        "\n",
        "    # def __init__(self):\n",
        "    #     super(BERT, self).__init__()\n",
        "    #     self.embedding = Embedding().to(device)\n",
        "    #     self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
        "    #     self.fc = nn.Linear(d_model, d_model).to(device)\n",
        "    #     self.activ = nn.Tanh()\n",
        "    #     self.linear = nn.Linear(d_model, d_model).to(device)\n",
        "    #     self.norm = nn.LayerNorm(d_model).to(device)\n",
        "    #     self.classifier = nn.Linear(d_model, 2).to(device)\n",
        "    #     # decoder is shared with embedding layer\n",
        "    #     embed_weight = self.embedding.tok_embed.weight\n",
        "    #     n_vocab, n_dim = embed_weight.size()\n",
        "    #     self.decoder = nn.Linear(n_dim, n_vocab, bias=False).to(device)\n",
        "    #     self.decoder.weight = embed_weight\n",
        "    #     self.decoder_bias = nn.Parameter(torch.zeros(n_vocab)).to(device)\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.embedding = Embedding()\n",
        "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "        self.activ = nn.Tanh()\n",
        "        self.linear = nn.Linear(d_model, d_model)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.classifier = nn.Linear(d_model, 2)\n",
        "        # decoder is shared with embedding layer\n",
        "        embed_weight = self.embedding.tok_embed.weight\n",
        "        n_vocab, n_dim = embed_weight.size()\n",
        "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
        "        self.decoder.weight = embed_weight\n",
        "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
        "\n",
        "    def forward(self, input_ids, segment_ids, masked_pos):\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "        masked_pos = masked_pos.to(device)\n",
        "\n",
        "        output = self.embedding(input_ids, segment_ids)\n",
        "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)\n",
        "        for layer in self.layers:\n",
        "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
        "\n",
        "\n",
        "        # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
        "\n",
        "        # 1. predict next sentence\n",
        "        # it will be decided by first token(CLS)\n",
        "        h_pooled   = self.activ(self.fc(output[:, 0])) # [batch_size, d_model]\n",
        "        logits_nsp = self.classifier(h_pooled) # [batch_size, 2]\n",
        "\n",
        "        # 2. predict the masked token\n",
        "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) # [batch_size, max_pred, d_model]\n",
        "        h_masked = torch.gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
        "        h_masked  = self.norm(F.gelu(self.linear(h_masked)))\n",
        "        logits_lm = self.decoder(h_masked) + self.decoder_bias # [batch_size, max_pred, n_vocab]\n",
        "\n",
        "        return logits_lm, logits_nsp, output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MomTFvw6ZXwc"
      },
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UAG3SEP4UbU",
        "outputId": "602849e0-c73f-411d-be96-219f893467f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 loss = 100.723152\n",
            "Epoch: 02 loss = 135.139938\n",
            "Epoch: 03 loss = 100.601234\n",
            "Epoch: 04 loss = 101.605026\n"
          ]
        }
      ],
      "source": [
        "num_epoch = 5\n",
        "model = BERT()\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# batch = make_batch()\n",
        "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
        "\n",
        "input_ids = input_ids.to(device)  # Move tensors to GPU\n",
        "segment_ids = segment_ids.to(device)  # Move tensors to GPU\n",
        "masked_tokens = masked_tokens.to(device)  # Move tensors to GPU\n",
        "masked_pos = masked_pos.to(device)  # Move tensors to GPU\n",
        "isNext = isNext.to(device)  # Move tensors to GPU\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    optimizer.zero_grad()\n",
        "    logits_lm, logits_nsp, output = model(input_ids, segment_ids, masked_pos)\n",
        "    #logits_lm: (bs, max_mask, vocab_size) ==> (6, 5, 34)\n",
        "    #logits_nsp: (bs, yes/no) ==> (6, 2)\n",
        "    #1. mlm loss\n",
        "    #logits_lm.transpose: (bs, vocab_size, max_mask) vs. masked_tokens: (bs, max_mask)\n",
        "    loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens) # for masked LM\n",
        "    loss_lm = (loss_lm.float()).mean()\n",
        "    #2. nsp loss\n",
        "    #logits_nsp: (bs, 2) vs. isNext: (bs, )\n",
        "    loss_nsp = criterion(logits_nsp, isNext) # for sentence classification\n",
        "\n",
        "    #3. combine loss\n",
        "    loss = loss_lm + loss_nsp\n",
        "    if epoch % 1 == 0 and epoch != 0:\n",
        "        print('Epoch:', '%02d' % (epoch), 'loss =', '{:.6f}'.format(loss))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-LCT1IqKjf-x"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "bert_args['vocab_size'] = vocab_size\n",
        "\n",
        "pickle.dump(bert_args, open('bert.args', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_args"
      ],
      "metadata": {
        "id": "88VBXO2Ulg01"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "me9_M3EUMVlX"
      },
      "outputs": [],
      "source": [
        "save_path = '' + 'bert-from-scratch.pt'\n",
        "torch.save(model.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvmHjPndZXwc"
      },
      "source": [
        "## 5. Inference\n",
        "\n",
        "Since our dataset is very small, it won't work very well, but just for the sake of demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k1qHdqTMuZQ",
        "outputId": "34a48350-891e-417e-c0ca-7263f87640b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD3K8T6B4YJp",
        "outputId": "1dee626e-5948-4b75-a7bd-961fef5f4078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'sum', 'i', 'look', 'for', 'another', 'good', 'year', '[MASK]', 'the', 'electronics', 'industry', 'in', '1961', 'with', 'total', 'o', 'increasing', 'about', '7%', 'to', '$108', 'billion', 'despite', 'the', 'uncertainties', 'in', '[MASK]', 'business', 'outlook', 'generally', 'as', '[SEP]', 'later', 'vehicle', 'purchase', 'assignment', 'and', 'use', 'policiesprobably', 'the', 'most', 'important', 'of', 'all', 'matters', 'for', 'review', 'are', 'the', '[MASK]', 'administrative', 'policies', 'governing', 'the', 'purchase', 'assignment', 'use', 'and', 'management', 'of', '[MASK]', 'vehicles', 'the', '[SEP]']\n",
            "masked tokens (words) :  ['sales', 'state', 'for', 'broad', 'the']\n",
            "masked tokens list :  [985, 6662, 5896, 5436, 3479]\n",
            "masked tokens (words) :  ['11%', '11%', '11%', '11%', '11%']\n",
            "predict masked tokens list :  [347, 347, 347, 347, 347]\n",
            "1\n",
            "isNext :  False\n",
            "predict isNext :  True\n"
          ]
        }
      ],
      "source": [
        "# Predict mask tokens ans isNext\n",
        "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[2]))\n",
        "print([id2word[w.item()] for w in input_ids[0] if id2word[w.item()] != '[PAD]'])\n",
        "\n",
        "logits_lm, logits_nsp, output = model(input_ids, segment_ids, masked_pos)\n",
        "#logits_lm:  (1, max_mask, vocab_size) ==> (1, 5, 34)\n",
        "#logits_nsp: (1, yes/no) ==> (1, 2)\n",
        "\n",
        "#predict masked tokens\n",
        "#max the probability along the vocab dim (2), [1] is the indices of the max, and [0] is the first value\n",
        "logits_lm = logits_lm.data.max(2)[1][0].cpu().data.numpy()\n",
        "#note that zero is padding we add to the masked_tokens\n",
        "print('masked tokens (words) : ',[id2word[pos.item()] for pos in masked_tokens[0]])\n",
        "print('masked tokens list : ',[pos.item() for pos in masked_tokens[0]])\n",
        "print('masked tokens (words) : ',[id2word[pos.item()] for pos in logits_lm])\n",
        "print('predict masked tokens list : ', [pos for pos in logits_lm])\n",
        "\n",
        "#predict nsp\n",
        "logits_nsp = logits_nsp.data.max(1)[1][0].cpu().data.numpy()\n",
        "print(logits_nsp)\n",
        "print('isNext : ', True if isNext else False)\n",
        "print('predict isNext : ',True if logits_nsp else False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FxXlKwdZXwi"
      },
      "source": [
        "Trying a bigger dataset should be able to see the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "HFX4FLk5Nb05"
      },
      "outputs": [],
      "source": [
        "dest = \"/content/drive/MyDrive/Colab_Notebooks/NLP/Assignment5/models/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LTCR9NQ4NwZW",
        "outputId": "88d3c343-5027-4ff6-c23f-0a48317c47e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bert-from-scratch.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "save_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "sYH2w4VENd8D"
      },
      "outputs": [],
      "source": [
        "!cp $save_path $dest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rFPfWt0GngiI"
      },
      "outputs": [],
      "source": [
        "!cp bert.args $dest"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}