{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install torchdata\n",
        "# !pip3 install torchtext\n",
        "!pip3 install portalocker\n",
        "!pip3 install datasets\n",
        "!pip3 install spacy\n",
        "!python3 -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2LCoMloG3nQ",
        "outputId": "80d85e2f-23f2-4bbf-9214-cb9a87403cdd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.8.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxmBzIhnGYyj"
      },
      "source": [
        "# [Sentence-BERT](https://arxiv.org/pdf/1908.10084.pdf)\n",
        "\n",
        "[Reference Code](https://www.pinecone.io/learn/series/nlp/train-sentence-transformers-softmax/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ws-iyHSGYyk",
        "outputId": "89899dcf-b80c-472d-febe-3eb9f2e84a48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import re\n",
        "from   random import *\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Set GPU device\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
        "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4GavkcHGYym"
      },
      "source": [
        "## 1. Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuYtLpduGYym"
      },
      "source": [
        "### Train, Test, Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ0vLihrGYym",
        "outputId": "2e28283f-039e-4305-a45f-a9884141190d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'premise': Value(dtype='string', id=None),\n",
              "  'hypothesis': Value(dtype='string', id=None),\n",
              "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
              "  'idx': Value(dtype='int32', id=None)},\n",
              " {'premise': Value(dtype='string', id=None),\n",
              "  'hypothesis': Value(dtype='string', id=None),\n",
              "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import datasets\n",
        "snli = datasets.load_dataset('snli')\n",
        "mnli = datasets.load_dataset('glue', 'mnli')\n",
        "mnli['train'].features, snli['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_m5T-DDGYym",
        "outputId": "5c20d24d-bb43-4d14-bbe8-4fc726ef4b81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# List of datasets to remove 'idx' column from\n",
        "mnli.column_names.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HnDuD3kxGYyn"
      },
      "outputs": [],
      "source": [
        "# Remove 'idx' column from each dataset\n",
        "for column_names in mnli.column_names.keys():\n",
        "    mnli[column_names] = mnli[column_names].remove_columns('idx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSRZfyNEGYyn",
        "outputId": "c06dc1ba-bd26-45c9-b2f9-bcccaea8e552"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "mnli.column_names.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGJLEKefGYyn",
        "outputId": "c0de649d-5de8-4533-9fd9-915102fc0202"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2]), array([-1,  0,  1,  2]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
        "#snli also have -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1ldgI_VrGYyn"
      },
      "outputs": [],
      "source": [
        "# there are -1 values in the label feature, these are where no class could be decided so we remove\n",
        "snli = snli.filter(\n",
        "    lambda x: 0 if x['label'] == -1 else 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCBFyIB_GYyo",
        "outputId": "34d2f3f3-c64b-4d6a-b900-f9afdacb13ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2]), array([0, 1, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
        "#snli also have -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clUhQ3H-GYyo",
        "outputId": "65cc0ac8-ac0c-4dfa-f9ce-358aefa190a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Assuming you have your two DatasetDict objects named snli and mnli\n",
        "from datasets import DatasetDict\n",
        "# Merge the two DatasetDict objects\n",
        "raw_dataset = DatasetDict({\n",
        "    'train': datasets.concatenate_datasets([snli['train'], mnli['train']]).shuffle(seed=55).select(list(range(1000))),\n",
        "    'test': datasets.concatenate_datasets([snli['test'], mnli['test_mismatched']]).shuffle(seed=55).select(list(range(100))),\n",
        "    'validation': datasets.concatenate_datasets([snli['validation'], mnli['validation_mismatched']]).shuffle(seed=55).select(list(range(1000)))\n",
        "})\n",
        "#remove .select(list(range(1000))) in order to use full dataset\n",
        "# Now, merged_dataset_dict contains the combined datasets from snli and mnli\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBXKS1UZGYyo"
      },
      "source": [
        "## 2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gDNuAqOxGYyo"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pEAH0yICGYyp"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    max_seq_length = 128\n",
        "    padding = 'max_length'\n",
        "    # Tokenize the premise\n",
        "    premise_result = tokenizer(\n",
        "        examples['premise'], padding=padding, max_length=max_seq_length, truncation=True)\n",
        "    #num_rows, max_seq_length\n",
        "    # Tokenize the hypothesis\n",
        "    hypothesis_result = tokenizer(\n",
        "        examples['hypothesis'], padding=padding, max_length=max_seq_length, truncation=True)\n",
        "    #num_rows, max_seq_length\n",
        "    # Extract labels\n",
        "    labels = examples[\"label\"]\n",
        "    #num_rows\n",
        "    return {\n",
        "        \"premise_input_ids\": premise_result[\"input_ids\"],\n",
        "        \"premise_attention_mask\": premise_result[\"attention_mask\"],\n",
        "        \"hypothesis_input_ids\": hypothesis_result[\"input_ids\"],\n",
        "        \"hypothesis_attention_mask\": hypothesis_result[\"attention_mask\"],\n",
        "        \"labels\" : labels\n",
        "    }\n",
        "\n",
        "tokenized_datasets = raw_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        ")\n",
        "\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['premise','hypothesis','label'])\n",
        "tokenized_datasets.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgaTyCVEGYyp",
        "outputId": "4df77c18-b8be-4447-a073-0d7f1cd04864"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCVd03piGYyp"
      },
      "source": [
        "## 3. Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qVzxtm63GYyp"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# initialize the dataloader\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets['train'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets['validation'],\n",
        "    batch_size=batch_size\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_datasets['test'],\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_ynKpOWGYyp",
        "outputId": "d015909f-5aef-404b-d114-6ec3bc41d40b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 128])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "for batch in train_dataloader:\n",
        "    print(batch['premise_input_ids'].shape)\n",
        "    print(batch['premise_attention_mask'].shape)\n",
        "    print(batch['hypothesis_input_ids'].shape)\n",
        "    print(batch['hypothesis_attention_mask'].shape)\n",
        "    print(batch['labels'].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTW9Y0I5GYyq"
      },
      "source": [
        "## 4. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ig3XS-AGYyq",
        "outputId": "25cda6f9-7ba7-4054-9d2c-6b066bff2631"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# start from a pretrained bert-base-uncased model\n",
        "from transformers import BertTokenizer, BertModel\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3n652oIGYyq"
      },
      "source": [
        "### Pooling\n",
        "SBERT adds a pooling operation to the output of BERT / RoBERTa to derive a fixed sized sentence embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XGvE9epaGYyq"
      },
      "outputs": [],
      "source": [
        "# define mean pooling function\n",
        "def mean_pool(token_embeds, attention_mask):\n",
        "    # reshape attention_mask to cover 768-dimension embeddings\n",
        "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
        "        token_embeds.size()\n",
        "    ).float()\n",
        "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
        "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
        "        in_mask.sum(1), min=1e-9\n",
        "    )\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKhuY9dNGYyq"
      },
      "source": [
        "## 5. Loss Function\n",
        "\n",
        "## Classification Objective Function\n",
        "We concatenate the sentence embeddings $u$ and $v$ with the element-wise difference  $\\lvert u - v \\rvert $ and multiply the result with the trainable weight  $ W_t ∈  \\mathbb{R}^{3n \\times k}  $:\n",
        "\n",
        "$ o = \\text{softmax}\\left(W^T \\cdot \\left(u, v, \\lvert u - v \\rvert\\right)\\right) $\n",
        "\n",
        "where $n$ is the dimension of the sentence embeddings and k the number of labels. We optimize cross-entropy loss. This structure is depicted in Figure 1.\n",
        "\n",
        "## Regression Objective Function.\n",
        "The cosine similarity between the two sentence embeddings $u$ and $v$ is computed (Figure 2). We use means quared-error loss as the objective function.\n",
        "\n",
        "(Manhatten / Euclidean distance, semantically  similar sentences can be found.)\n",
        "\n",
        "<img src=\"./figures/sbert-architecture.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "stbyorbrGYyq"
      },
      "outputs": [],
      "source": [
        "def configurations(u,v):\n",
        "    # build the |u-v| tensor\n",
        "    uv = torch.sub(u, v)   # batch_size,hidden_dim\n",
        "    uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
        "\n",
        "    # concatenate u, v, |u-v|\n",
        "    x = torch.cat([u, v, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
        "    return x\n",
        "\n",
        "def cosine_similarity(u, v):\n",
        "    dot_product = np.dot(u, v)\n",
        "    norm_u = np.linalg.norm(u)\n",
        "    norm_v = np.linalg.norm(v)\n",
        "    similarity = dot_product / (norm_u * norm_v)\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKiEAg3QGYyr"
      },
      "source": [
        "<img src=\"./figures/sbert-ablation.png\" width=\"350\" height=\"300\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "k68arIjDGYyr"
      },
      "outputs": [],
      "source": [
        "classifier_head = torch.nn.Linear(768*3, 3).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "optimizer_classifier = torch.optim.Adam(classifier_head.parameters(), lr=2e-5)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UFbdR15GYyr",
        "outputId": "8ea62e15-cad8-437d-dfc3-856b9205cccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# and setup a warmup for the first ~10% steps\n",
        "total_steps = int(len(raw_dataset) / batch_size)\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "\t\toptimizer, num_warmup_steps=warmup_steps,\n",
        "  \tnum_training_steps=total_steps - warmup_steps\n",
        ")\n",
        "\n",
        "# then during the training loop we update the scheduler per step\n",
        "scheduler.step()\n",
        "\n",
        "scheduler_classifier = get_linear_schedule_with_warmup(\n",
        "\t\toptimizer_classifier, num_warmup_steps=warmup_steps,\n",
        "  \tnum_training_steps=total_steps - warmup_steps\n",
        ")\n",
        "\n",
        "# then during the training loop we update the scheduler per step\n",
        "scheduler_classifier.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_yBP0bMGYyr"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "c74bf7ad5a2e4b8f93e3d69824f17679",
            "dfe788cb024e40f69a56c181f3dbd2ba",
            "7196b32d6b5947ebb8a8e001082f2045",
            "c69f1816df48432986451fd578efdeb7",
            "baf7dcf17f854c85a78b6d29d26e4bd8",
            "8c74779be4054ddebf4a51529524d9d7",
            "7bc291150c3a4dfa9fc7fb3db4133996",
            "9f6104ea5ff0409c905ff31901151d2a",
            "94ad2d21e9bc40cdb032b5f952e5a989",
            "bc17a8458d854c418877923973c79e11",
            "02ef49d3388c46dcb93ce880a15ca6b1"
          ]
        },
        "id": "nvwXo6x_GYyr",
        "outputId": "0ad8bc8a-8459-4a49-9799-f81690360cc6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c74bf7ad5a2e4b8f93e3d69824f17679"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | loss = 1.140016| Accuracy = 34.599999999999994%\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "num_epoch = 1\n",
        "# 1 epoch should be enough, increase if wanted\n",
        "accuracy = 0\n",
        "count = 0\n",
        "for epoch in range(num_epoch):\n",
        "    model.train()\n",
        "    classifier_head.train()\n",
        "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
        "    for step, batch in enumerate(tqdm(train_dataloader, leave=True)):\n",
        "        # zero all gradients on each new step\n",
        "        optimizer.zero_grad()\n",
        "        optimizer_classifier.zero_grad()\n",
        "\n",
        "        # prepare batches and more all to the active device\n",
        "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
        "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
        "        attention_a = batch['premise_attention_mask'].to(device)\n",
        "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
        "        label = batch['labels'].to(device)\n",
        "\n",
        "        # extract token embeddings from BERT at last_hidden_state\n",
        "        u = model(inputs_ids_a, attention_mask=attention_a)\n",
        "        v = model(inputs_ids_b, attention_mask=attention_b)\n",
        "\n",
        "        u_last_hidden_state = u.last_hidden_state # all token embeddings A = batch_size, seq_len, hidden_dim\n",
        "        v_last_hidden_state = v.last_hidden_state # all token embeddings B = batch_size, seq_len, hidden_dim\n",
        "\n",
        "         # get the mean pooled vectors\n",
        "        u_mean_pool = mean_pool(u_last_hidden_state, attention_a) # batch_size, hidden_dim\n",
        "        v_mean_pool = mean_pool(v_last_hidden_state, attention_b) # batch_size, hidden_dim\n",
        "\n",
        "        # build the |u-v| tensor\n",
        "        uv = torch.sub(u_mean_pool, v_mean_pool)   # batch_size,hidden_dim\n",
        "        uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
        "\n",
        "        # concatenate u, v, |u-v|\n",
        "        x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
        "\n",
        "        # process concatenated tensor through classifier_head\n",
        "        x = classifier_head(x) #batch_size, classifer\n",
        "\n",
        "        for out, lab in zip(x, label):\n",
        "            count = count + 1\n",
        "            if torch.argmax(out).item() == lab.item():\n",
        "                accuracy = accuracy + 1\n",
        "\n",
        "        # calculate the 'softmax-loss' between predicted and true label\n",
        "        loss = criterion(x, label)\n",
        "\n",
        "        # using loss, calculate gradients and then optimizerize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer_classifier.step()\n",
        "\n",
        "        scheduler.step() # update learning rate scheduler\n",
        "        scheduler_classifier.step()\n",
        "\n",
        "    print(f'Epoch: {epoch + 1} | loss = {loss.item():.6f}| Accuracy = {(accuracy / count) * 100}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYoEcLOFGYyr",
        "outputId": "aabe3346-7868-492f-fb5f-a30903feb8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Cosine Similarity: 0.7661\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "classifier_head.eval()\n",
        "total_similarity = 0\n",
        "with torch.no_grad():\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        # prepare batches and more all to the active device\n",
        "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
        "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
        "        attention_a = batch['premise_attention_mask'].to(device)\n",
        "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
        "        label = batch['labels'].to(device)\n",
        "\n",
        "        # extract token embeddings from BERT at last_hidden_state\n",
        "        u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
        "        v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
        "\n",
        "        # get the mean pooled vectors\n",
        "        u_mean_pool = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
        "        v_mean_pool = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
        "\n",
        "        similarity_score = cosine_similarity(u_mean_pool, v_mean_pool)\n",
        "        total_similarity += similarity_score\n",
        "\n",
        "average_similarity = total_similarity / len(eval_dataloader)\n",
        "print(f\"Average Cosine Similarity: {average_similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baU6CzZfGYys"
      },
      "source": [
        "## 7. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZieSEyVrGYys",
        "outputId": "16fda190-45d0-4b19-871b-a9be78605670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.8057\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_similarity(model, tokenizer, sentence_a, sentence_b, device):\n",
        "    # Tokenize and convert sentences to input IDs and attention masks\n",
        "    inputs_a = tokenizer(sentence_a, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "    inputs_b = tokenizer(sentence_b, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "\n",
        "    # Move input IDs and attention masks to the active device\n",
        "    inputs_ids_a = inputs_a['input_ids']\n",
        "    attention_a = inputs_a['attention_mask']\n",
        "    inputs_ids_b = inputs_b['input_ids']\n",
        "    attention_b = inputs_b['attention_mask']\n",
        "\n",
        "    # Extract token embeddings from BERT\n",
        "    u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
        "    v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
        "\n",
        "    # Get the mean-pooled vectors\n",
        "    u = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
        "    v = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity_score = cosine_similarity(u.reshape(1, -1), v.reshape(1, -1))[0, 0]\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "# Example usage:\n",
        "sentence_a = 'Your contribution helped make it possible for us to provide our students with a quality education.'\n",
        "sentence_b = \"Your contributions were of no help with our students' education.\"\n",
        "similarity = calculate_similarity(model, tokenizer, sentence_a, sentence_b, device)\n",
        "print(f\"Cosine Similarity: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IJEu6fcLGYys"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c74bf7ad5a2e4b8f93e3d69824f17679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfe788cb024e40f69a56c181f3dbd2ba",
              "IPY_MODEL_7196b32d6b5947ebb8a8e001082f2045",
              "IPY_MODEL_c69f1816df48432986451fd578efdeb7"
            ],
            "layout": "IPY_MODEL_baf7dcf17f854c85a78b6d29d26e4bd8"
          }
        },
        "dfe788cb024e40f69a56c181f3dbd2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c74779be4054ddebf4a51529524d9d7",
            "placeholder": "​",
            "style": "IPY_MODEL_7bc291150c3a4dfa9fc7fb3db4133996",
            "value": "100%"
          }
        },
        "7196b32d6b5947ebb8a8e001082f2045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f6104ea5ff0409c905ff31901151d2a",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94ad2d21e9bc40cdb032b5f952e5a989",
            "value": 32
          }
        },
        "c69f1816df48432986451fd578efdeb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc17a8458d854c418877923973c79e11",
            "placeholder": "​",
            "style": "IPY_MODEL_02ef49d3388c46dcb93ce880a15ca6b1",
            "value": " 32/32 [00:13&lt;00:00,  2.97it/s]"
          }
        },
        "baf7dcf17f854c85a78b6d29d26e4bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c74779be4054ddebf4a51529524d9d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bc291150c3a4dfa9fc7fb3db4133996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f6104ea5ff0409c905ff31901151d2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ad2d21e9bc40cdb032b5f952e5a989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc17a8458d854c418877923973c79e11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ef49d3388c46dcb93ce880a15ca6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}